# training related parameters
exp_name: "pixelar"
results_dir: "outputs"
global_seed: 0

model:
  gpt_model: GPT-B
  gpt_type: 'c2i'
  cls_token_num: 1
  dropout_p: 0.1
  drop_path_rate: 0.0
  token_dropout_p: 0.1
  codebook_size: 256
  codebook_embed_dim: 8
  downsample_size: 16
  patchifier: 'linear' # [linear, cnn]

dataset:
  path: data/imagenet/ILSVRC/Data/CLS-LOC/train
  image_size: 256
  num_classes: 1000

accelerator:
  gradient_accumulation_steps: 2
  mixed_precision: bf16
  inductor_mode: default

optimizer:
  lr: 1e-4
  weight_decay: 5e-2
  beta1: 0.9
  beta2: 0.95
  max_grad_norm: 1.0

training:
  num_workers: 24
  global_batch_size: 384
  epochs: 300
  wandb:
    wandb_offline: true

checkpoint:
  log_every: 100
  log_with: wandb
  visualize_every: 500 # every 10 log intervals, do one visualization
  visualize_num: 8
  disk_location: null

resume_dir: null
